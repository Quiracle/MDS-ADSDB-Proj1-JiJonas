{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean_database(db_path, output_db_path):\n",
    "    # Connect to the DuckDB database\n",
    "    conn = duckdb.connect(db_path)\n",
    "    \n",
    "    # Get list of all tables in the database\n",
    "    tables = conn.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'main';\").fetchall()\n",
    "    \n",
    "    # Iterate over each table and load into a DataFrame\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        print(f\"Reading and cleaning table: {table_name}\")\n",
    "        try:\n",
    "            # Read the table into a DataFrame\n",
    "            df = conn.execute(f\"SELECT * FROM {table_name}\").fetchdf()\n",
    "            \n",
    "            # Deduplication: Remove duplicate rows\n",
    "            df = df.drop_duplicates()\n",
    "            \n",
    "            # Consistent formatting: Ensure consistent datetime format\n",
    "            for col in df.select_dtypes(include=['object']).columns:\n",
    "                try:\n",
    "                    df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            \n",
    "            # Quality checks: Handle missing values by dropping or imputing\n",
    "            missing_value_threshold = 0.5\n",
    "            for col in df.columns:\n",
    "                if df[col].isnull().mean() > missing_value_threshold:\n",
    "                    # Drop columns with more than 50% missing values\n",
    "                    df = df.drop(columns=[col])\n",
    "                else:\n",
    "                    # Fill missing values with the median for numeric columns or mode for categorical columns\n",
    "                    if df[col].dtype in ['int64', 'float64']:\n",
    "                        df[col].fillna(df[col].median(), inplace=True)\n",
    "                    else:\n",
    "                        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "            \n",
    "            # Data normalization: Normalize numeric columns\n",
    "            numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "            scaler = MinMaxScaler()\n",
    "            df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "            \n",
    "            # Save the cleaned DataFrame to a new DuckDB database\n",
    "            if not os.path.exists(output_db_path):\n",
    "                output_conn = duckdb.connect(output_db_path)\n",
    "                output_conn.register('cleaned_df', df)\n",
    "                output_conn.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM cleaned_df\")\n",
    "                output_conn.close()\n",
    "            else:\n",
    "                output_conn = duckdb.connect(output_db_path)\n",
    "                try:\n",
    "                    output_conn.execute(f\"INSERT INTO {table_name} SELECT * FROM cleaned_df\")\n",
    "                except duckdb.CatalogException:\n",
    "                    output_conn.register('cleaned_df', df)\n",
    "                    output_conn.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM cleaned_df\")\n",
    "                output_conn.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error while cleaning table '{table_name}': {e}\")\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and cleaning table: fotocasa\n",
      "Error while cleaning table 'fotocasa': unhashable type: 'numpy.ndarray'\n",
      "Reading and cleaning table: idealista\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while cleaning table 'idealista': 'utf-8' codec can't decode byte 0xd5 in position 134: invalid continuation byte\n",
      "Reading and cleaning table: income\n",
      "Error while cleaning table 'income': 'utf-8' codec can't decode byte 0xd5 in position 134: invalid continuation byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_16748\\3981229590.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True).dt.strftime('%d/%m/%Y')\n"
     ]
    }
   ],
   "source": [
    "read_and_clean_database('../trusted_zone/trusted.db', 'path/to/treated_trusted.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
