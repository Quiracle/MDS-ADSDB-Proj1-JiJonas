{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tables_by_keyword(db_path, keyword):\n",
    "    # Connect to the DuckDB database\n",
    "    conn = duckdb.connect(db_path)\n",
    "    \n",
    "    # Query to get all table names containing the specified keyword\n",
    "    query = f\"SELECT table_name FROM information_schema.tables WHERE table_name ILIKE '%{keyword}%';\"\n",
    "    table_names = conn.execute(query).fetchall()\n",
    "\n",
    "    # Extract table names from query result\n",
    "    table_names = [name[0] for name in table_names]\n",
    "\n",
    "    # Read each table into a DataFrame and merge them\n",
    "    merged_df = pd.DataFrame()\n",
    "    for table_name in table_names:\n",
    "        try:\n",
    "            df = conn.execute(f'SELECT * FROM {table_name}').fetchdf()\n",
    "            merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error while processing table '{table_name}': {e}\")\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def save_merged_table_to_new_db(merged_df, new_db_path, table_name):\n",
    "    # Connect to the new DuckDB database\n",
    "    conn = duckdb.connect(new_db_path)\n",
    "    \n",
    "    # Drop the table if it exists\n",
    "    conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "    \n",
    "    # Replace problematic objects with NaN to avoid type conversion issues\n",
    "    merged_df = merged_df.applymap(lambda x: np.nan if isinstance(x, dict) else x)\n",
    "    \n",
    "    # Save the merged DataFrame to the new database\n",
    "    conn.register('merged_df', merged_df)\n",
    "    conn.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM merged_df\")\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "def merge_and_save_all_groups(db_path, new_db_path):\n",
    "    # Define the keywords to group tables by\n",
    "    keywords = ['idealista', 'income', 'fotocasa']\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        # Merge tables by keyword\n",
    "        merged_df = merge_tables_by_keyword(db_path, keyword)\n",
    "        \n",
    "        # Save the merged DataFrame to the new database\n",
    "        save_merged_table_to_new_db(merged_df, new_db_path, table_name=keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unwanted_columns(db_path, table_name):\n",
    "    # Connect to the DuckDB database\n",
    "    conn = duckdb.connect(db_path)\n",
    "    \n",
    "    # List of columns to drop\n",
    "    keyword_list = [\n",
    "        'thumbnail','externalReference','numPhotos','showAddress',\n",
    "        'url','distance','hasVideo','detailedType','suggestedTexts',\n",
    "        'hasPlan','has3DTour','has360','hasStaging','topNewDevelopment',\n",
    "        'parkingSpace','json','index','priceInfo','description',\n",
    "        'topPlus','highlight','newDevelopmentFinished'\n",
    "    ]\n",
    "    \n",
    "    # Iterate over the keyword list and drop each column if it exists\n",
    "    for keyword in keyword_list:\n",
    "        try:\n",
    "            conn.execute(f\"ALTER TABLE {table_name} DROP COLUMN IF EXISTS {keyword}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while dropping column '{keyword}': {e}\")\n",
    "    \n",
    "    # Save the modified table to a new database\n",
    "    modified_df = conn.execute(f\"SELECT * FROM {table_name}\").fetchdf()\n",
    "    conn.close()\n",
    "    \n",
    "    # Connect to the output database and save the modified table\n",
    "    output_conn = duckdb.connect(db_path)\n",
    "    output_conn.register('modified_df', modified_df)\n",
    "\n",
    "    # Drop the table if it exists\n",
    "    output_conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "    output_conn.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM modified_df\")\n",
    "    output_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_19096\\1515188529.py:34: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  merged_df = merged_df.applymap(lambda x: np.nan if isinstance(x, dict) else x)\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_19096\\1515188529.py:34: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  merged_df = merged_df.applymap(lambda x: np.nan if isinstance(x, dict) else x)\n",
      "C:\\Users\\Zhengyong Ji\\AppData\\Local\\Temp\\ipykernel_19096\\1515188529.py:34: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  merged_df = merged_df.applymap(lambda x: np.nan if isinstance(x, dict) else x)\n"
     ]
    }
   ],
   "source": [
    "merge_and_save_all_groups('../formatted_zone/formatted.db', '../trusted_zone/trusted.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_unwanted_columns('../trusted_zone/trusted.db', 'idealista')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
